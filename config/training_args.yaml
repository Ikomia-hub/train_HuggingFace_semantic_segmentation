# --------------------
# - Optional config file for expert mode:  
# - This is a template for the Advanced YAML config file
# - Hyperparameters and other costumizations settings related to the training loop.
# - The list of taining arguments to be added can be found here:
# - https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments
# --------------------


learning_rate: 0.0005
num_train_epochs: 20
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
save_steps: 5
save_total_limit: 3
evaluation_strategy: "steps"
save_strategy: "steps"
save_steps: 20
eval_steps: 20
logging_steps: 1
gradient_accumulation_steps: 1
eval_accumulation_steps: 5
load_best_model_at_end: True
push_to_hub: False
hub_model_id: hub_model_id
hub_strategy: "end"
load_best_model_at_end: True
remove_unused_columns: False
optim: "adamw_hf"
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 0.00000001
resume_from_checkpoint: None
report_to: "mlflow"
